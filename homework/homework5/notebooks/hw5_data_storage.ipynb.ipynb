{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dff0e86-eea8-4133-b0d2-69f93a602dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW -> /Users/mayurakshi/bootcamp_mayurakshi_biswas/homework/homework5/notebooks/data/raw\n",
      "PROC -> /Users/mayurakshi/bootcamp_mayurakshi_biswas/homework/homework5/notebooks/data/processed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>149.319545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>149.897366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>149.833188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>149.508149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>151.411527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date ticker       price\n",
       "0 2024-01-01   AAPL  149.319545\n",
       "1 2024-01-02   AAPL  149.897366\n",
       "2 2024-01-03   AAPL  149.833188\n",
       "3 2024-01-04   AAPL  149.508149\n",
       "4 2024-01-05   AAPL  151.411527"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, pathlib, datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set RAW and PROCESSED directories from .env, with defaults\n",
    "RAW = pathlib.Path(os.getenv('DATA_DIR_RAW', 'data/raw'))\n",
    "PROC = pathlib.Path(os.getenv('DATA_DIR_PROCESSED', 'data/processed'))\n",
    "\n",
    "# Make sure directories exist\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "PROC.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('RAW ->', RAW.resolve())\n",
    "print('PROC ->', PROC.resolve())\n",
    "\n",
    "# Create sample DataFrame\n",
    "dates = pd.date_range('2024-01-01', periods=20, freq='D')\n",
    "df = pd.DataFrame({\n",
    "    'date': dates,\n",
    "    'ticker': ['AAPL']*20,\n",
    "    'price': 150 + np.random.randn(20).cumsum()\n",
    "})\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7b4bd5f-0c62-4664-a222-0cc528055b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parquet save failed: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n",
      "A suitable version of pyarrow or fastparquet is required for parquet support.\n",
      "Trying to import the above resulted in these errors:\n",
      " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
      " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\n",
      "CSV saved -> data/raw/sample_20250820-235130.csv\n",
      "Parquet saved -> data/processed/sample_20250820-235130.parquet\n"
     ]
    }
   ],
   "source": [
    "# Helper function for timestamp\n",
    "def ts():\n",
    "    return dt.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "# File paths\n",
    "csv_path = RAW / f\"sample_{ts()}.csv\"\n",
    "pq_path  = PROC / f\"sample_{ts()}.parquet\"\n",
    "\n",
    "# Save CSV and Parquet\n",
    "df.to_csv(csv_path, index=False)\n",
    "try:\n",
    "    df.to_parquet(pq_path)\n",
    "except Exception as e:\n",
    "    print('Parquet save failed:', e)\n",
    "\n",
    "print(\"CSV saved ->\", csv_path)\n",
    "print(\"Parquet saved ->\", pq_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10e698e9-5af5-4789-9c28-25c0deccc5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Validation: {'shape_equal': True, 'date_is_datetime': True, 'price_is_numeric': True}\n",
      "Parquet read skipped: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n",
      "A suitable version of pyarrow or fastparquet is required for parquet support.\n",
      "Trying to import the above resulted in these errors:\n",
      " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
      " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\n"
     ]
    }
   ],
   "source": [
    "# Reload CSV\n",
    "df_csv = pd.read_csv(csv_path, parse_dates=['date'])\n",
    "\n",
    "# Validation function\n",
    "def validate_loaded(original, reloaded):\n",
    "    checks = {\n",
    "        'shape_equal': original.shape == reloaded.shape,\n",
    "        'date_is_datetime': pd.api.types.is_datetime64_any_dtype(reloaded['date']) if 'date' in reloaded.columns else False,\n",
    "        'price_is_numeric': pd.api.types.is_numeric_dtype(reloaded['price']) if 'price' in reloaded.columns else False,\n",
    "    }\n",
    "    return checks\n",
    "\n",
    "# Validate CSV\n",
    "csv_validation = validate_loaded(df, df_csv)\n",
    "print(\"CSV Validation:\", csv_validation)\n",
    "\n",
    "# Optionally, try Parquet if engine available\n",
    "try:\n",
    "    df_pq = pd.read_parquet(pq_path)\n",
    "    pq_validation = validate_loaded(df, df_pq)\n",
    "    print(\"Parquet Validation:\", pq_validation)\n",
    "except Exception as e:\n",
    "    print(\"Parquet read skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf8e06a-ce3d-4a7b-a45d-a8a1afe0dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t, pathlib\n",
    "\n",
    "# Detect format by file extension\n",
    "def detect_format(path: t.Union[str, pathlib.Path]):\n",
    "    s = str(path).lower()\n",
    "    if s.endswith('.csv'): return 'csv'\n",
    "    if s.endswith('.parquet') or s.endswith('.pq') or s.endswith('.parq'): return 'parquet'\n",
    "    raise ValueError('Unsupported format: ' + s)\n",
    "\n",
    "# Write DataFrame to CSV or Parquet\n",
    "def write_df(df: pd.DataFrame, path: t.Union[str, pathlib.Path]):\n",
    "    p = pathlib.Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fmt = detect_format(p)\n",
    "    if fmt == 'csv':\n",
    "        df.to_csv(p, index=False)\n",
    "    else:\n",
    "        try:\n",
    "            df.to_parquet(p)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "    print(f\"{fmt.upper()} saved -> {p}\")\n",
    "    return p\n",
    "\n",
    "# Read DataFrame from CSV or Parquet\n",
    "def read_df(path: t.Union[str, pathlib.Path]):\n",
    "    p = pathlib.Path(path)\n",
    "    fmt = detect_format(p)\n",
    "    if fmt == 'csv':\n",
    "        return pd.read_csv(p, parse_dates=['date']) if 'date' in pd.read_csv(p, nrows=0).columns else pd.read_csv(p)\n",
    "    else:\n",
    "        try:\n",
    "            return pd.read_parquet(p)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6469546a-b2b1-4a87-9574-337cb777d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV saved -> data/raw/util_20250820-235421.csv\n",
      "Skipping Parquet demo: Parquet engine not available. Install pyarrow or fastparquet.\n"
     ]
    }
   ],
   "source": [
    "# Demo usage of the utilities\n",
    "p_csv = RAW / f\"util_{dt.datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\"\n",
    "p_pq  = PROC / f\"util_{dt.datetime.now().strftime('%Y%m%d-%H%M%S')}.parquet\"\n",
    "\n",
    "# Write and read CSV\n",
    "write_df(df, p_csv)\n",
    "df_csv_loaded = read_df(p_csv)\n",
    "df_csv_loaded.head()\n",
    "\n",
    "# Write and read Parquet (will fail if pyarrow/fastparquet missing)\n",
    "try:\n",
    "    write_df(df, p_pq)\n",
    "    df_pq_loaded = read_df(p_pq)\n",
    "    df_pq_loaded.head()\n",
    "except RuntimeError as e:\n",
    "    print('Skipping Parquet demo:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41c8f9bf-0c0a-43bf-932f-47457385fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Validation: {'shape_equal': True, 'date_is_datetime': True, 'price_is_numeric': True}\n"
     ]
    }
   ],
   "source": [
    "# Validation of CSV reload\n",
    "validation_result = validate_loaded(df, df_csv_loaded)\n",
    "print(\"CSV Validation:\", validation_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78f45f82-74f8-408d-9ab4-fadc54c4c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t, pathlib\n",
    "\n",
    "def detect_format(path: t.Union[str, pathlib.Path]):\n",
    "    s = str(path).lower()\n",
    "    if s.endswith('.csv'): return 'csv'\n",
    "    if s.endswith('.parquet') or s.endswith('.pq') or s.endswith('.parq'): return 'parquet'\n",
    "    raise ValueError('Unsupported format: ' + s)\n",
    "\n",
    "def write_df(df: pd.DataFrame, path: t.Union[str, pathlib.Path]):\n",
    "    p = pathlib.Path(path)\n",
    "    p.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fmt = detect_format(p)\n",
    "    if fmt == 'csv':\n",
    "        df.to_csv(p, index=False)\n",
    "    else:\n",
    "        try:\n",
    "            df.to_parquet(p)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n",
    "    return p\n",
    "\n",
    "def read_df(path: t.Union[str, pathlib.Path]):\n",
    "    p = pathlib.Path(path)\n",
    "    fmt = detect_format(p)\n",
    "    if fmt == 'csv':\n",
    "        df0 = pd.read_csv(p, nrows=0)\n",
    "        parse_dates = ['date'] if 'date' in df0.columns else None\n",
    "        return pd.read_csv(p, parse_dates=parse_dates)\n",
    "    else:\n",
    "        try:\n",
    "            return pd.read_parquet(p)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError('Parquet engine not available. Install pyarrow or fastparquet.') from e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78e3ba21-7e51-4715-b781-d736e80f3b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Parquet util demo: Parquet engine not available. Install pyarrow or fastparquet.\n",
      "CSV Validation: {'shape_equal': True, 'date_is_datetime': True, 'price_is_numeric': True}\n",
      "Parquet read skipped: Parquet engine not available. Install pyarrow or fastparquet.\n"
     ]
    }
   ],
   "source": [
    "# Demo using utilities\n",
    "p_csv = RAW / f\"util_{dt.datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\"\n",
    "p_pq  = PROC / f\"util_{dt.datetime.now().strftime('%Y%m%d-%H%M%S')}.parquet\"\n",
    "\n",
    "# Write CSV and Parquet\n",
    "write_df(df, p_csv)\n",
    "try:\n",
    "    write_df(df, p_pq)\n",
    "except RuntimeError as e:\n",
    "    print('Skipping Parquet util demo:', e)\n",
    "\n",
    "# Read back CSV (Parquet read skipped if engine missing)\n",
    "df_csv_loaded = read_df(p_csv)\n",
    "print('CSV Validation:', validate_loaded(df, df_csv_loaded))\n",
    "\n",
    "try:\n",
    "    df_pq_loaded = read_df(p_pq)\n",
    "    print('Parquet Validation:', validate_loaded(df, df_pq_loaded))\n",
    "except RuntimeError as e:\n",
    "    print('Parquet read skipped:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a545e8-9877-4f16-ae5d-b64b02191fc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
